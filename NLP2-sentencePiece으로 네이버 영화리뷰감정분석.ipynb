{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentencePiece로 네이버 영화 리뷰 감정 분석\n",
    "\n",
    "## 분석 모델의 목적 \n",
    "\n",
    "네이버 영화 댓글로 구성된 데이터를 input으로 받으면, 긍정적인 반응(label 1) 인지 부정적인 반응(label 2) 인지인지 판단. \n",
    "\n",
    "이미 exp node 4에서 KoNLPY의 형태소 분석기를 사용해서 텍스트를 전처리했었음.\n",
    "\n",
    "이번 프로젝트에서는 tokenizer를 sentencepiece로 바꾸어서 다시 풀어보아 성능을 비교하는 것이 목적."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "raw2.tolist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentencePiece 설치\n",
    "\n",
    "SentencePiece는 SentencePiece는 Google에서 제공하는 오픈소스 기반 Sentence Tokenizer/Detokenizer 로서, BPE와 unigram 2가지 subword 토크나이징 모델 중 하나를 선택해서 사용할 수 있도록 패키징한 것임.  \n",
    "\n",
    "* [google/sentencepiece](https://github.com/google/sentencepiece)\n",
    "\n",
    "SentencePiece는 딥러닝 자연어처리 모델의 앞부분에 사용할 목적으로 최적화되어 있는데, 최근 pretrained model들이 거의 대부분 SentencePiece를 tokenizer로 채용하면서 사실상 **표준**의 역할을 하고 있음. \n",
    "\n",
    " SentencePiece는 python에서 전용 라이브러리는 아니지만 편리한 파이썬 wrapper를 아래와 같이 제공하고 있음.\n",
    " \n",
    "``` terminal \n",
    "$ pip install sentencepiece\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SentencePiece 모델 학습\n",
    "\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentbence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer 함수 작성\n",
    "\n",
    ">\n",
    "> 1) 매개변수로 토큰화된 문장의 list를 전달하는 대신 온전한 문장의 list 를 전달합니다.\n",
    ">\n",
    "> 2) 생성된 vocab 파일을 읽어와 { <word> : <idx> } 형태를 가지는 word_index 사전과 { <idx> : <word>} 형태를 가지는 index_word > 사전을 생성하고 함께 반환합니다.\n",
    "> \n",
    "> 3) 리턴값인 tensor 는 앞의 함수와 동일하게 토큰화한 후 Encoding된 문장입니다. 바로 학습에 사용할 수 있게 Padding은 당연히 해야겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n",
      "None \n",
      "-----------------------------------\n",
      "          id                                           document  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "print(train_data.info(),\"\\n-----------------------------------\\n\",train_data.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train data는 0부터 149999 즉 150000개가 있습니다.            \n",
    "데이터는 index, id, document,label로 이루어져있는것을 확인 할 수 있었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = train_data['document'].values\n",
    "raw = raw.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    sen = str(sen)\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "댓글이다 보니 짧은 리뷰들이 많은 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아\n",
      "잼\n",
      "1\n",
      "4\n",
      "4\n",
      "굿\n",
      "짱\n",
      "휴\n",
      ".\n",
      "1\n",
      "굿\n",
      "음\n",
      "?\n",
      "?\n",
      "ㅎ\n",
      "굿\n",
      "ㅋ\n",
      "굿\n",
      "즐\n",
      "♥\n",
      "굳\n",
      "ㅋ\n",
      "네\n",
      "ㅎ\n",
      "ㅋ\n",
      "굿\n",
      "ㅇ\n",
      "k\n",
      ".\n",
      "굿\n",
      "굿\n",
      "굳\n",
      "ㅠ\n",
      "?\n",
      "1\n",
      "ㅋ\n",
      "굿\n",
      "쒯\n",
      "굿\n",
      "굿\n",
      "굳\n",
      "♬\n",
      "굿\n",
      "토\n",
      "ㅋ\n",
      "ㅋ\n",
      "굿\n",
      "ㅋ\n",
      "굿\n",
      "O\n",
      "똥\n",
      "ㅎ\n",
      ".\n",
      "굿\n",
      "ㅎ\n",
      "짱\n",
      "굳\n",
      "굿\n",
      "굿\n",
      "짱\n",
      "?\n",
      "z\n",
      "굿\n",
      "짱\n",
      "음\n",
      "굳\n",
      "ㅇ\n",
      "헐\n",
      "굳\n",
      "굳\n",
      "굿\n",
      "굿\n",
      "굿\n",
      "삼\n",
      "꽝\n",
      "굿\n",
      "굿\n",
      "굿\n",
      "굿\n",
      "ㅎ\n",
      "굳\n",
      "굿\n",
      "4\n",
      "!\n",
      "?\n",
      "ㅎ\n",
      "1\n",
      "굳\n",
      ".\n",
      "ㅎ\n",
      "풉\n",
      "아\n",
      "굿\n",
      "똥\n",
      "ㅅ\n",
      "왜\n",
      "ㄴ\n",
      "굳\n",
      "쉣\n",
      "봐\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        sen = str(sen)\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "check_sentence_with_length(raw, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Index: 1\n",
      "Outlier Index: 2\n",
      "Outlier Index: 3\n",
      "Outlier Index: 4\n",
      "Outlier Index: 5\n",
      "Outlier Index: 6\n",
      "Outlier Index: 7\n",
      "Outlier Index: 8\n",
      "Outlier Index: 9\n",
      "Outlier Index: 10\n",
      "Outlier Index: 11\n",
      "Outlier Index: 12\n",
      "Outlier Index: 13\n",
      "Outlier Index: 14\n",
      "Outlier Index: 15\n",
      "Outlier Index: 16\n",
      "Outlier Index: 17\n",
      "Outlier Index: 18\n",
      "Outlier Index: 19\n",
      "Outlier Index: 20\n",
      "Outlier Index: 21\n",
      "Outlier Index: 22\n",
      "Outlier Index: 23\n",
      "Outlier Index: 24\n",
      "Outlier Index: 25\n",
      "Outlier Index: 26\n",
      "Outlier Index: 27\n",
      "Outlier Index: 28\n",
      "Outlier Index: 29\n",
      "Outlier Index: 30\n",
      "Outlier Index: 31\n",
      "Outlier Index: 32\n",
      "Outlier Index: 33\n",
      "Outlier Index: 34\n",
      "Outlier Index: 35\n",
      "Outlier Index: 36\n",
      "Outlier Index: 37\n",
      "Outlier Index: 38\n",
      "Outlier Index: 39\n",
      "Outlier Index: 40\n",
      "Outlier Index: 41\n",
      "Outlier Index: 42\n",
      "Outlier Index: 43\n",
      "Outlier Index: 44\n",
      "Outlier Index: 45\n",
      "Outlier Index: 46\n",
      "Outlier Index: 47\n",
      "Outlier Index: 48\n",
      "Outlier Index: 49\n",
      "Outlier Index: 50\n",
      "Outlier Index: 51\n",
      "Outlier Index: 52\n",
      "Outlier Index: 53\n",
      "Outlier Index: 54\n",
      "Outlier Index: 55\n",
      "Outlier Index: 56\n",
      "Outlier Index: 57\n",
      "Outlier Index: 58\n",
      "Outlier Index: 59\n",
      "Outlier Index: 60\n",
      "Outlier Index: 61\n",
      "Outlier Index: 62\n",
      "Outlier Index: 63\n",
      "Outlier Index: 64\n",
      "Outlier Index: 65\n",
      "Outlier Index: 66\n",
      "Outlier Index: 67\n",
      "Outlier Index: 68\n",
      "Outlier Index: 69\n",
      "Outlier Index: 70\n",
      "Outlier Index: 71\n",
      "Outlier Index: 72\n",
      "Outlier Index: 73\n",
      "Outlier Index: 74\n",
      "Outlier Index: 75\n",
      "Outlier Index: 76\n",
      "Outlier Index: 77\n",
      "Outlier Index: 78\n",
      "Outlier Index: 79\n",
      "Outlier Index: 80\n",
      "Outlier Index: 81\n",
      "Outlier Index: 82\n",
      "Outlier Index: 83\n",
      "Outlier Index: 84\n",
      "Outlier Index: 85\n",
      "Outlier Index: 86\n",
      "Outlier Index: 87\n",
      "Outlier Index: 88\n",
      "Outlier Index: 89\n",
      "Outlier Index: 90\n",
      "Outlier Index: 91\n",
      "Outlier Index: 92\n",
      "Outlier Index: 93\n",
      "Outlier Index: 94\n",
      "Outlier Index: 95\n",
      "Outlier Index: 96\n",
      "Outlier Index: 97\n",
      "Outlier Index: 98\n",
      "Outlier Index: 99\n",
      "Outlier Index: 100\n",
      "Outlier Index: 101\n",
      "Outlier Index: 102\n",
      "Outlier Index: 103\n",
      "Outlier Index: 104\n",
      "Outlier Index: 105\n",
      "Outlier Index: 106\n",
      "Outlier Index: 107\n",
      "Outlier Index: 108\n",
      "Outlier Index: 109\n",
      "Outlier Index: 112\n",
      "Outlier Index: 114\n",
      "Outlier Index: 118\n",
      "Outlier Index: 123\n",
      "Outlier Index: 125\n",
      "Outlier Index: 128\n",
      "Outlier Index: 129\n",
      "Outlier Index: 130\n",
      "Outlier Index: 131\n",
      "Outlier Index: 132\n",
      "Outlier Index: 133\n",
      "Outlier Index: 134\n",
      "Outlier Index: 135\n",
      "Outlier Index: 136\n",
      "Outlier Index: 137\n",
      "Outlier Index: 138\n",
      "Outlier Index: 139\n",
      "Outlier Index: 140\n"
     ]
    }
   ],
   "source": [
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장의 수가 1500을 초과하는 문장 길이를 추출합니다.\n",
    "    if _sum > 156:\n",
    "        print(\"Outlier Index:\", idx+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"스폰으로 먹고사는 방송이라 어쩔수 없다고 하지만. 이건 그냥 비현실적인 자동차만;...독일3사&슈퍼카 홍보 프로그램도 아니구.대중적인 자동차 방송으로 이루어 졌으면 합니다. 보는내내 \"\"카탈로그 책자\"\"를 \"\"동영상으로 보여주는 방송\"\" 같아서 씁쓸하네요.!\"\n",
      "\"\"\"니 짓은 생각않고, 웬 복수!\"\"의 교훈이라! 그럼 \"\"서바이벌 액션\"\"으로 홍보하면 안되지! 초반 45분은 멋지게 열더니.. 억지 반전, 하드고어로 시간끌다가, 허둥지둥 화해로 끝내버리네. 90분 러닝타임에 엔딩자막만 11분 틀어주는 해괴망측한 영화~!\"\n",
      "\"2007.02.25_ 벌교의 한 국밥집_ 점심: \"\"갸는 첫째고, 저 놈은 우리 둘째~\"\" 재문: \"\"아줌마! 미안해~ 그냥.. 아줌마! 나 그 남방 잘 어울려ㅠ_ㅠ?\"\" 대식에게 복수하려던 1주일 전_ 대식의 엄마를 먼저 만났다. 사랑의 꽃남방도..^-^o\"\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(raw, 146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 146183\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    sen = str(sen)\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sen = str(sen)\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150000개의 데이터에서 중복을 줄이자 146183를 얻을 수 있었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "짧은 문장은 뻬고 139 길이까지의 문장만 사용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 139\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(str(s)) < max_len) & (len(str(s)) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ssac4 ssac4 374947  4월 18 19:34 korean_spm.model\r\n",
      "-rw-r--r-- 1 ssac4 ssac4 144420  4월 18 19:34 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1407, 10, 389, 15, 1340, 10, 139, 17, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentbence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 575 2905   13 1155 2303    4    0    0    0    0]\n",
      " [1466 2438  312  570   10    3   16 7935  853    8]]\n"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentencePiece 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor , word_index, index_word = sp_tokenize(s, filtered_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터로더 구성\n",
    "\n",
    "\n",
    "나만의 data_loader를 만들어 보는 것으로 시작합니다.           \n",
    "data_loader에서 수행해야할 것들은 아래와 같습니다.\n",
    "\n",
    "* 데이터의 중복 제거                                   \n",
    "* NaN 결측치 제거         \n",
    "* 한국어 토크나이저로 토큰화                     \n",
    "* 불용어(Stopwords) 제거                 \n",
    "* 사전word_to_index 구성                 \n",
    "* 텍스트 스트링을 사전 인덱스 스트링으로 변환                    \n",
    "* X_train, y_train, X_test, y_test, word_to_index 리턴                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True) # 중복값 제거 \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True) # 중복값 제거 \n",
    "    train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") #정규식으로 한글이 아닌것은 제거 \n",
    "    test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규식 한글이 아닌것은 제거\n",
    "    train_data['document'].replace('', np.nan, inplace=True) #공백값만 존재하면 nan로 변경\n",
    "    test_data['document'].replace('', np.nan, inplace=True) # 공백값만 존재하면 nan로 변경\n",
    "    train_data = train_data.dropna(how = 'any')  # na값 제거 \n",
    "    test_data = test_data.dropna(how = 'any')  #na값 제거 \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_data함수를 만든이후 함수를 통해\n",
    "X_train, y_train,X_test, y_test, word_to_index를 원본 train_data,test_data에서 읽어왔습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그후 word_to_index를 이용하여 반대로 index_to_word를 만들었고,      \n",
    "encode,decode 데이터 역시 만들 수 있었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 67, 895, 33, 214, 15, 28, 699]\n",
      "[[27, 67, 895, 33, 214, 15, 28, 699], [977, 481, 491, 636, 4, 110, 1554, 48, 866, 949, 11, 38, 364], [19, 192, 2]]\n",
      "145791\n",
      "48995\n",
      "194786\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(X_train[:3])\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_train+X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 전처리를 끝낸후 X_train은 145791, X_test는 48995가 되었음을 확인 할 수 있었습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아마 여러분들은 네이버 영화리뷰 감정분석 태스크를 한 번쯤은 다루어 보았을 것입니다. 한국어로 된 corpus를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전처리해서 RNN 모델을 분류기로 사용했을 것입니다.\n",
    "\n",
    "만약 이 문제에서 tokenizer를 sentencepiece로 바꾸어 다시 풀어본다면 더 성능이 좋아질까요? 비교해 보는 것도 흥미로울 것입니다.\n",
    "\n",
    "네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "\n",
    "학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    "\n",
    "구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "\n",
    "KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "\n",
    "(보너스) SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
    "\n",
    "Word Vector는 활용할 필요가 없습니다. 활용이 가능하지도 않을 것입니다.\n",
    "\n",
    "머지않아 SentencePiece와 BERT 등의 pretrained 모델을 함께 활용하는 태스크를 다루게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|--|--|\n",
    "|1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?|코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?|\n",
    "|2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?|SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.|\n",
    "|3. SentencePiece의 성능을 다각도로 비교분석하였는가?|SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

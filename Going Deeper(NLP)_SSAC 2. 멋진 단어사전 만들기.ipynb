{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1. 들어가며\n",
    "\n",
    "퍼즐 맞추는 것을 즐기시나요? 머리가 복잡해 어딘가에 몰두하고 싶거나, 작은 성취가 고플 땐 퍼즐이 아주 좋답니다. 난이도 별로, 그림 별로 정말 많은 퍼즐이 있고 심지어는 아예 그림이 없는 퍼즐도 있다고 해요 (백야 퍼즐이라고 불린답니다). 필자는 너무 조각 수가 많지 않고, 예쁜 명화를 채워 넣는 퍼즐을 간간히 즐깁니다!\n",
    "\n",
    "문득 생각하길, 문장을 만드는 것이 마치 퍼즐 맞추기 같더군요. 조각들이 제각기 다른 모양을 가지고 있고, 맞는 위치에 있더라도 그림이 다를 수 있죠. 모양과 그림이 모두 맞아야 비로소 작품이 완성되는 것, 마치 문맥과 문법을 고려하는 것과 꼭 닮았습니다! 대신 우리의 문장 퍼즐은 단 하나의 작품을 목표로 하지 않죠. 올바르게 맞춰진 퍼즐, 그 위의 그림이 어울린다면 그 자체로 작품입니다!\n",
    "\n",
    "이번 코스에서 우리가 배울 것이 바로 문장을 조각내는 방법입니다. 어떤 문장을 일정한 기준을 갖는 단어로 쪼개는 것, 그것은 곧 퍼즐 조각을 나누는 것과 같죠! 지나치게 잘게 쪼개면 넓은 그림을 담을 수 없어 되 맞추기 어려울 것이고, 너무 크게 쪼갰다간 퍼즐이 너무 쉬워지고 말 겁니다.\n",
    "\n",
    "이번 코스에선 문장 데이터를 직접 토큰화하며 어떤 방법이 가장 적합한 단어 조각을 만들어 내는지 실습해보도록 하겠습니다.\n",
    "\n",
    "## 준비물\n",
    "이번 코스에서는 KoNLPy, 그중에서도 가장 성능이 준수한 MeCab클래스를 활용해 실습하도록 하겠습니다!\n",
    "\n",
    "실습할 MeCab 클래스는 Windows에서 지원이 되지 않습니다. 우분투 환경이 준비되어 있다면 우분투 환경에서 실습하시길 바랍니다! 만일 우분투 환경에 접근이 어렵다면 구글에서 제공하는 Colab 서비스를 사용해보세요.\n",
    "\n",
    "* [Google Colaboratory](https://colab.research.google.com/notebooks/intro.ipynb#recent=true)\n",
    "                        \n",
    "[우분투 환경에서 설치하기] 1) 우분투 환경에서 커널을 열어 jdk를 먼저 설치해줍시다.\n",
    "\n",
    "``` termianl\n",
    "$ sudo apt-get install g++ openjdk-8-jdk\n",
    "```\n",
    "\n",
    "2) 설치가 완료되었다면 curl을 이용해 mecab을 다운받아 실행 시켜 줍니다.\n",
    "\n",
    "``` termianl\n",
    "$ bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
    "```\n",
    "3) 그리고 마지막으로 konlpy를 설치해 줍니다.\n",
    "\n",
    "``` termianl\n",
    "$ pip install konlpy\n",
    "```\n",
    "\n",
    "그 외 다른 OS의 설치 방법이 궁금하시다면 아래 공식 문서를 참고하시길 바라요!\n",
    "\n",
    "[설치하기 - KoNLPy 0.5.2 documentation](http://konlpy.org/ko/latest/install/)\n",
    "\n",
    "설치가 완료된 후엔 아주 간편하게 import 하여 형태소 분석기를 사용하실 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['자연어', '처리', '가', '너무', '재밌', '어서', '밥', '먹', '는', '것', '도', '가끔', '까먹', '어요']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "print(mecab.morphs('자연어처리가너무재밌어서밥먹는것도가끔까먹어요'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2. 데이터 다운로드 및 분석\n",
    "\n",
    "먼저 프로젝트에 사용될 라이브러리를 import 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 학습환경을 구성하고 데이터를 다운받아 보겠습니다.\n",
    "\n",
    "``` terminal \n",
    "$ wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "$ mkdir -p ~/aiffel/sp_tokenizer/data\n",
    "$ mv korean-english-park.train.tar.gz ~/aiffel/sp_tokenizer/data\n",
    "$ cd ~/aiffel/sp_tokenizer/data\n",
    "$ tar -xzvf korean-english-park.train.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko'\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내려받은 데이터는 한국어의 형태소 분석과 품사 태깅, 기계 번역 연구를 위해 공개된 데이터입니다. 이번에 사용할 데이터는 한국어-영어 병렬을 이루는 말뭉치 중 한국어 부분으로, 전체 병렬 말뭉치는 후에 번역기를 만들며 사용할 예정입니다!\n",
    "\n",
    "혹시 다른 종류의 데이터가 궁금하시다면 아래 Github를 방문해보세요!\n",
    "\n",
    "* [jungyeul/korean-parallel-corpora](https://github.com/jungyeul/korean-parallel-corpora)\n",
    "\n",
    "자, 데이터가 우리 손으로 들어왔으니 씹고 뜯고 맛볼 차례입니다! 멋진 시각화를 동반한 통계적 분석…까지는 하지 않고요. 최소한의 분석으로 데이터가 얼마나 있고, 어떻게 생겼는지 정도를 직접 확인해 봅시다.\n",
    "\n",
    "문장은 위에서 확인한 것처럼 94123개가 포함되어 있습니다. 우리는 각 문장이 어느 정도의 길이를 가지는지 확인해보겠습니다! 이 과정을 거치면 지나치게 긴 데이터를 삭제하거나 (연산량을 감소시켜 학습 속도가 빨라집니다!) 지나치게 짧은 데이터를 검증 (무조건 필요가 없지는 않습니다, 단어 ↔ 단어 라면 번역을 학습할 수 있겠죠!) 할 수 있습니다. 즉, 데이터를 얼마나 사용할지 타협점을 정의할 수 있습니다.\n",
    "\n",
    "아래 소스는 문장의 최단 길이, 최장 길이, 평균 길이를 구한 후 문장 길이 분포를 막대그래프로 표현해주는 소스입니다. raw 변수는 앞서 다운로드받은 데이터가 담긴 변수입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 999\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균길이: 60.78048935966767\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    length = len(sen)\n",
    "    if min_len > length: men_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "    \n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균길이:\", sum_len / len(raw))\n",
    "\n",
    "\n",
    "sentence_length = np.zeros((max_len),dtype = np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "    \n",
    "plt.bar(range(max_len), sentence_length, width = 1.0 )\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최단 길이 1, 최장 길이 377… 그리고 제법 그럴듯한 막대그래프가 나왔습니다만, 이 결과를 확인하고 드는 생각은 아래와 크게 다르지 않으실 거예요..!\n",
    "\n",
    "1) 길이 1 짜리 문장은 도대체 어떻게 생겨먹었지?\n",
    "\n",
    "2) 앞에 치솟는 임의의 구간은 뭐지? 유의미한 데이터가 담겨있는 부분인가?\n",
    "\n",
    "3) 어디서부터 어디까지 잘라서 쓰지?\n",
    "\n",
    "궁금증을 하나하나 해결해 봅시다! 대체 길이가 1인 문장은 뭘까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "’\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count> 100: return\n",
    "            \n",
    "check_sentence_with_length(raw,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오잉? 하마터면 완전 노이즈인 데이터를 그대로 사용할 뻔했습니다! 왠지 길이별로 확인할 일이 많을 것 같아 함수를 미리 정의해두었는데, 이를 이용해 확인이 필요해 보이는 문장은 모두 확인해보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier index 11\n",
      "Outlier index 19\n",
      "Outlier index 21\n"
     ]
    }
   ],
   "source": [
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장의 수가 1500을 초과하는 문장 길이를 추출하빈다.\n",
    "    if _sum > 1500:\n",
    "        print(\"Outlier index\", idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라고 조던이 말했다.\n",
      "- 모르고 있습니다.\n",
      "- 네, 보이는군요.\n",
      "디즈니사만이 아니다.\n",
      "큰 파티는 아니지요.\n",
      "의자는 비어 있었다.\n",
      "이 일은 계속됩니다.\n",
      "나는 크게 실망했다.\n",
      "그 이유는 간단하다.\n",
      "이력서와 자기 소개서\n",
      "시대가 변하고 있다.\n",
      "는 돌발질문을 했다.\n",
      "9. 몇 분간의 명상\n",
      "하와이, 빅 아일랜드\n",
      "키스를 잘 하는 방법\n",
      "키스를 잘 하는 방법\n",
      "스피어스가 뚱뚱한가?\n",
      "산 위를 나는 느낌.\n",
      "세 시간쯤 걸었을까?\n",
      "(아직 읽고있습니까?\n",
      "처음에는 장난이었다.\n",
      "우리는 운이 좋았다.\n",
      "아기가 숨을 멈출 때\n",
      "건물 전체 무너져내려\n",
      "그녀의 아름다운 눈.\n",
      "대답은 다음과 같다.\n",
      "\"사과할 것이 없다.\n",
      "폭탄테러가 공포 유발\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "조금은 새침한 샬롯？\n",
      "조금은 새침한 샬롯？\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n"
     ]
    }
   ],
   "source": [
    "check_sentence_with_length(raw, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런… 심지어 중복에 대한 처리도 제대로 하지 않았었네요. 중복 제거는 Python의 기본 자료형 set을 활용할 겁니다. set은 집합을 정의하는 자료형인데, 중복을 허용하지 않아 변환 과정에서 자동으로 중복된 요소를 제거해주거든요! 대신 list의 순서가 뒤죽박죽될 수 있으니, 만약 번역 데이터처럼 쌍을 이뤄야 하는 경우라면 주의해서 사용하셔야 합니다!\n",
    "\n",
    "중복을 제거한 후, 앞에서 분포를 확인한 소스를 다시 실행 시켜 보겠습니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 77591\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제서야 깔끔한 데이터를 얻은 느낌이 드네요. 데이터의 개수도 17000개가량 줄어 77591 개가 되었습니다.\n",
    "\n",
    "마지막으로 '모든 데이터를 다 사용할 것이냐' 가 문제인데, 후에 미니 배치를 만들 것을 생각하면 모든 데이터를 다 사용하는 것은 연산 측면에서 비효율적입니다. 미니 배치 특성상 각 데이터의 크기가 모두 동일해야 하기 때문에 가장 긴 데이터를 기준으로 Padding 처리를 해야 합니다. 위의 데이터에서 만약 길이가 100인 문장까지만 사용한다면 데이터는 [ (77591 - 길이 100 초과 문장 수) x 100 ] 의 형태를 갖겠지만 모두 사용할 경우 [ 77591 x 377 ] 로 전자보다 최소 3.7배 큰 메모리를 차지합니다. 학습 시간도 그만큼 더 오래 걸리고요.\n",
    "\n",
    "길이별로 정렬하여 미니 배치를 구성해 Padding을 최소화하는 방법도 있지만 이는 데이터를 섞는 데 편향성이 생길 수 있으므로 지양해야 합니다. 여기서는 길이 150 이상의 데이터를 제거하고 사용하도록 할게요!\n",
    "\n",
    "그리고 앞서 확인한 것처럼 너무 짧은 데이터는 오히려 노이즈로 작용할 수 있습니다. 따라서 길이가 10 미만인 데이터도 제거하도록 하죠!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "                                                                      \n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype = np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 최종적인 데이터 분포를 확인하면 위와 같습니다!\n",
    "\n",
    "\n",
    "이제 정말 사용할 준비가 된 것 같죠? 본격적인 작업을 시작해봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3. 공백 기반 토큰화\n",
    "\n",
    "배운 순서대로, 먼저 공백 기반 토큰화를 진행해 봅시다!\n",
    "\n",
    "정제된 데이터를 공백 기반으로 토큰화하여 list에 저장한 후, 아래 tokenize() 함수를 사용해 단어 사전과 Tensor 데이터를 얻으세요! 그리고 단어 사전의 크기를 확인하세요!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그들은', '날조된', '서류', '및', '사망한', '남성과', '5세', '소년의', '신분증을', '사용했습니다.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_corpus[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정제된 데이터를 공백 기반으로 토큰화하여 저장하는 코드를 직접 작성해 보세요.\n",
    "split_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    split_corpus.append(kor.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 확인\n",
    "\n",
    "``` python \n",
    "split_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    split_corpus.append(kor.split())\n",
    "```\n",
    "정답을 확인해 보셨나요? 이제 공백 기반 토큰화를 진행한 후, 단어 사전의 길이를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Vocab Size: 237435\n"
     ]
    }
   ],
   "source": [
    "split_tensor, split_tokenizer = tokenize(split_corpus)\n",
    "\n",
    "print(\"Split Vocab Size:\", len(split_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드로 생성된 단어 사전을 확인해 볼 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 이\n",
      "1 : 밝혔다.\n",
      "2 : 있다.\n",
      "3 : 말했다.\n",
      "4 : 수\n",
      "5 : 있는\n",
      "6 : 그는\n",
      "7 : 대한\n",
      "8 : 위해\n",
      "9 : 전했다.\n",
      "10 : 지난\n",
      "11 : 이번\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(split_tokenizer.word_index):\n",
    "    print(idx, \":\", word)\n",
    "    \n",
    "    if idx > 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동사로 이루어진 단어를 살피면 공백 기반 토큰화의 문제점을 확인할 수 있습니다. 1번 단어인 밝혔다. 는 밝히다 , 밝다 등과 유사한 의미를 지니고 있음에도 전혀 다른 단어로 분류되겠죠? 이 때문에 공백 기반 토큰화는 불필요하게 큰 단어 사전을 가지게 되며 이는 연산량 증가로 이어집니다.\n",
    "\n",
    "만일 밝 + 혔다 라고 토큰화했다면 어땠을까요? 밝 + 히다, 밝 + 다 같은 구절이 등장했을 때, 공통된 어절인 밝 은 하나로 묶여 학습 중에 의미를 파악하기가 수월해지겠죠? 동시에 단어 사전도 효율적으로 축소될 것입니다. 이를 위해 형태소 분석기가 존재합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-4. 형태소 기반 토큰화\n",
    "\n",
    "한국어 형태소 분석기는 대표적으로 Khaiii와 KoNLPy가 사용됩니다. 이번 코스에서는 KoNLPy, 그중에서도 가장 성능이 준수한 MeCab클래스를 활용해 실습하도록 하겠습니다!\n",
    "\n",
    "앞서 작성했던 코드를 활용해 MeCab 기반으로 생성된 단어 사전과 Tensor 데이터를 얻어 봅시다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 사용한 코드를 활용해 MeCab 단어 사전을 만들어보세요. \n",
    "# Hint : mecab.morphs()를 사용해서 형태소분석을 합니다.\n",
    "def mecab_split(sentence):\n",
    "    # 코드를 작성하세요\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "mecab_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    mecab_corpus.append(mecab_split(kor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 확인\n",
    "``` python\n",
    "def mecab_split(sentence):\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "mecab_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    mecab_corpus.append(mecab_split(kor))\n",
    "```\n",
    "정답을 확인해 보셨나요? 이제 형태소 기반 토큰화를 진행한 후, 단어 사전의 길이를 확인해 봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeCab Vocab Size: 52279\n"
     ]
    }
   ],
   "source": [
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 실습했던 공백 기반 단어 사전에 비해 단어 수가 현저히 줄어든 것을 확인하셨을 겁니다. 이는 곧 연산량의 감소로 이어져 더 빠른 학습을 가능케 하고, 심지어 모델이 튜닝해야 하는 매개변수(Parameter) 수가 줄어들어 학습도 더 잘 된답니다! 적어도 한국어를 처리할 때는 공백 기반 토큰화를 절대 지양하셔야해요!\n",
    "\n",
    "다음 스텝에서 배울 SentencePiece같은 Subword 기반 토큰화보다 형태소 분석기가 좋은 성능을 내는 사례들이 종종 있는데요, ETRI에서 발표한 한국어 BERT 모델인 KorBERT가 대표적인 사례 중 하나입니다. 아래 웹페이지를 방문하면 모델의 자세한 구조뿐 아니라 KorBERT 모델을 5가지 자연어 처리 태스크를 기준으로 평가했던 흥미로운 결과까지 살펴보실 수 있습니다!\n",
    "\n",
    "* [공공 인공지능 오픈 API·DATA 서비스 포털](http://aiopen.etri.re.kr/service_dataset.php)\n",
    "\n",
    "자연어처리에서 토크나이저가 성능에 미치는 영향도가 크다는 것은 주지의 사실입니다만, 위 링크에서 발표된 평가결과를 살펴볼 때 몇가지 생각해 볼 만한 지점이 있습니다.\n",
    "\n",
    "아래 질문들에 대해 스스로 생각해 보고 본인의 생각을 정리해서 답변해 보시기 바랍니다. 사실 정답이 있는 문제는 아니기 때문입니다.\n",
    "\n",
    "> Q1. 구글의 Word Piece 기반 한국어 언어모델이 엑소브레인의 Word Piece 기반 한국어 언어모델보다 전체적으로 성능이 크게 떨어지는 것은 어떤 의미일까요? 여기서 유의해야 할 것은 언어모델(BERT)을 훈련시킨 원리는 동일하며, 토크나이저가 구성된 원리도 Word Piece 기반으로 동일하다는 점입니다.\n",
    "\n",
    "예시답안\n",
    "구글에서 배포한 BERT 모델은 한국어 전용 코퍼스를 바탕으로 훈련된 것이 아니라 Multilingual 코퍼스를 바탕으로 훈련된 것이며, Word Piece 모델 안에 포함된 subword 안에도 한국어가 아닌 여러 언어의 것이 섞여 있어서 한국어 자연어처리 태스크에 특화된 모델이 아닙니다. (상세한 내용은 https://github.com/google-research/bert 참조) \n",
    "\n",
    "\n",
    "엑소브레인의 것은 한국어 코퍼스에 특화된 형태로 언어모델과 토크나이저가 훈련된 것이므로 엑소브레인과 구글의 BERT 모델의 한국어 테스크 성능 차이는 한국어에 특화된 언어 모델을 구축했을 때 기대할 수 있는 성능 향상치로 해석할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q2. 엑소브레인의 BERT에 두 가지 버전이 있는데, 이 중 한국어 전용 형태소분석기 토크나이저를 사용한 버전이 WordPiece 모델 토크나이저를 사용한 버전보다 대체로 성능이 좋다는 것의 시사점은 무엇일까요?\n",
    "\n",
    "예시답안\n",
    "WordPiece 모델은 해당 언어의 문법적 및 의미적 사전정보가 반영되지 않은 채 순수하게 통계적인 빈도 기반으로 자주 사용되는 반복 패턴을 사전으로 등재해 놓은 것에 불과합니다. 그에 비해 정확한 한국어 문법과 의미정보를 바탕으로 개발된 형태소분석기가 정확하게 동작한다면 현재까지 가장 성능이 좋다고 알려진 Subword 기반의 토크나이저보다 더 성능이 좋을 수 있음을 보여 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q3. 정교한 형태소분석기를 활용한 모델의 성능이 더 좋을 수 있음에도 불구하고 현장에서 SentencePiece 같은 Subword 기반 토크나이저가 더욱 각광받는 이유는 무엇일까요?\n",
    "\n",
    "예시답안\n",
    "언어는 지속적으로 변합니다. 정교한 형태소분석기의 성능을 유지하기 위해서는 지속적인 데이터관리와 유지보수 작업이 필요합니다. \n",
    "\n",
    "\n",
    "그에 비해 SentencePiece 모델은 코퍼스데이터로부터 쉽게 추출해서 생성 가능하며, Subword 기반이기 때문에 새롭게 생성되는 단어에 대한 OOV(Out-of-Vocabulary) 문제에 대해서도 robust하게 대처할 수 있는 장점이 있습니다. 그리고 언어에 중립적이기 때문에 여러 언어가 섞여 나오는 텍스트를 처리하는 데에도 능합니다. \n",
    "\n",
    "\n",
    "무엇보다도, 특정 언어에 대한 부가지식이 없이도 엔지니어가 그 언어에 대한 작업을 손쉽게 진행할 수 있도록 해준다는 점과 그 언어에 특화된 토크나이저의 성능에 뒤지지 않거나 대체로 능가하는 성능을 보여주기 때문입니다.\n",
    "\n",
    "#### tensor -> sentence Decoding \n",
    "\n",
    "지금까지 문장을 Tensor로 Encoding하는 과정을 배웠는데요.\n",
    "후에 모델이 생성한 Tensor를 문장으로 Decoding하는 과정도 필요하겠죠?\n",
    "\n",
    "1) tokenizer.sequences_to_texts() 함수를 사용하여 Decoding\n",
    "\n",
    "2) tokenizer.index_word 를 사용하여 Decoding\n",
    "\n",
    "두 가지 방법으로 mecab_tensor[100] 을 원문으로 되돌려 보세요! (여기서 띄어쓰기는 고려하지 않습니다!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "편안 한 신발 도 도움 이 된다 .\n"
     ]
    }
   ],
   "source": [
    "texts = mecab_tokenizer.sequences_to_texts([mecab_tensor[100]])\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "코드 확인\n",
    "# Case 1\n",
    "texts = mecab_tokenizer.sequences_to_texts([mecab_tensor[100]])\n",
    "print(texts[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "편안 한 신발 도 도움 이 된다 . \n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "\n",
    "for w in mecab_tensor[100]:\n",
    "    if w == 0: continue\n",
    "    sentence += mecab_tokenizer.index_word[w] + \" \"\n",
    "    \n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 확인\n",
    "``` python\n",
    "# Case 2\n",
    "sentence = \"\"\n",
    "\n",
    "for w in mecab_tensor[100]:\n",
    "    if w == 0: continue\n",
    "    sentence += mecab_tokenizer.index_word[w] + \" \"\n",
    "\n",
    "print(sentence)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4926,   18, 2827,   40,  613,    3,  183,    1,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_tensor[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'편안'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_tokenizer.index_word[4926]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'편안 한 신발 도 도움 이 된다 .'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-5. 프로젝트: SentencePiece 사용하기\n",
    "### Step 1. SentencePiece 설치하기\n",
    "----------------\n",
    "SentencePiece는 SentencePiece는 Google에서 제공하는 오픈소스 기반 Sentence Tokenizer/Detokenizer 로서, BPE와 unigram 2가지 subword 토크나이징 모델 중 하나를 선택해서 사용할 수 있도록 패키징한 것입니다. 아래 링크의 페이지에서 상세한 내용을 파악할 수 있습니다.\n",
    "\n",
    "* [google/sentencepiece](https://github.com/google/sentencepiece)\n",
    "\n",
    "위 페이지의 서두에서도 언급하고 있듯, SentencePiece는 딥러닝 자연어처리 모델의 앞부분에 사용할 목적으로 최적화되어 있는데, 최근 pretrained model들이 거의 대부분 SentencePiece를 tokenizer로 채용하면서 사실상 표준의 역할을 하고 있습니다. 앞으로의 실습 과정에서 자주 만나게 될 것이므로 꼭 친숙해지시기를 당부드립니다.\n",
    "\n",
    "다음과 같이 설치를 진행합니다. SentencePiece는 python에서 쓰라고 만들어진 라이브러리는 아니지만 편리한 파이썬 wrapper를 아래와 같이 제공하고 있습니다.\n",
    "\n",
    "``` teminal\n",
    "$ pip install sentencepiece\n",
    "```\n",
    "\n",
    "### Step 2. SentencePiece 모델 학습\n",
    "앞서 배운 tokenize() 함수를 기억하나요? 다시 한번 상기시켜드릴게요!\n",
    "\n",
    "``` python\n",
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer\n",
    "```\n",
    "\n",
    "위와 같이 tf.keras.preprocessing.text.Tokenizer에 corpus를 주고 tokenizer.fit_on_texts(corpus)을 하면 토크나이저 내부적으로 단어사전과 토크나이저 기능을 corpus에 맞춤형으로 자동생성해 주는 것입니다.\n",
    "\n",
    "그럼 이를 위해서 SentencePiece 모델을 학습하는 과정을 거쳐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ssac4 ssac4 376896  4월 13 16:00 korean_spm.model\r\n",
      "-rw-r--r-- 1 ssac4 ssac4 146388  4월 13 16:00 korean_spm.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus: # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "        \n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드를 실행하면 정상적으로 SentencePiece 모델 학습이 완료된 후 koreanspm.model 파일과 koreanspm.vocab vocabulary 파일이 생성되었음을 확인할 수 있습니다.\n",
    "\n",
    "그럼 이렇게 학습된 SentencePiece 모델을 어떻게 활용하는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1244, 11, 306, 7, 3599, 11, 286, 38, 3]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentbence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SampleEncodeAsPieces 패러미터                  \n",
    "Pieces sampling                        \n",
    "deterministic-based: 1          \n",
    "probability-based: -1                     \n",
    "alpha =1.0: more likely sampling                \n",
    "alpha =0.0: uniformly sampling                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떻습니까? SentencePiece의 토크나이징 실력이 괜찮은 것 같습니다.\n",
    "\n",
    "### Step 3. Tokenizer 함수 작성\n",
    "우리는 위에서 훈련시킨 SentencePiece를 활용하여 위 함수와 유사한 기능을 하는 sp_tokenize() 함수를 정의할 겁니다. 하지만 SentencePiece가 동작하는 방식이 단순 토큰화와는 달라 완전히 동일하게는 정의하기 어렵습니다. 그러니 아래 조건을 만족하는 함수를 정의하도록 하습니다.\n",
    "\n",
    "1) 매개변수로 토큰화된 문장의 list를 전달하는 대신 온전한 문장의 list 를 전달합니다.\n",
    "\n",
    "2) 생성된 vocab 파일을 읽어와 { <word> : <idx> } 형태를 가지는 word_index 사전과 { <idx> : <word>} 형태를 가지는 index_word 사전을 생성하고 함께 반환합니다.\n",
    "\n",
    "3) 리턴값인 tensor 는 앞의 함수와 동일하게 토큰화한 후 Encoding된 문장입니다. 바로 학습에 사용할 수 있게 Padding은 당연히 해야겠죠?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "    tensor = []\n",
    "    \n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "        \n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "        \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    \n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        \n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "        \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1949 5662    5    4 7975 1983    3    0    0    0    0    0    0    0]\n",
      " [ 107 1638  101    4    0  419   11    4   14    0 1969    3    3    3]]\n"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 네이버 영화리뷰 감정분석 문제에 SentencePiece 적용해 보기\n",
    "\n",
    "아마 여러분들은 네이버 영화리뷰 감정분석 태스크를 한 번쯤은 다루어 보았을 것입니다. 한국어로 된 corpus를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전처리해서 RNN 모델을 분류기로 사용했을 것입니다.\n",
    "\n",
    "만약 이 문제에서 tokenizer를 sentencepiece로 바꾸어 다시 풀어본다면 더 성능이 좋아질까요? 비교해 보는 것도 흥미로울 것입니다.\n",
    "\n",
    "* 네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "\n",
    "* 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    " \n",
    "* 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "\n",
    "* KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "\n",
    "* (보너스) SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
    "\n",
    "* Word Vector는 활용할 필요가 없습니다. 활용이 가능하지도 않을 것입니다.\n",
    "\n",
    "머지않아 SentencePiece와 BERT 등의 pretrained 모델을 함께 활용하는 태스크를 다루게 될 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
